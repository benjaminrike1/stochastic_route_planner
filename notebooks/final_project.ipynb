{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4361aeb1-1e71-40ed-aea1-2a561cbef26b",
   "metadata": {},
   "source": [
    "## Application\n",
    "\n",
    "This notebook contains everything needed to run the routing application for our project. The notebook contains four main parts:\n",
    "1. Data loading and initalization of the network\n",
    "    - Here we take care of the necessities. More details about our data pipline can be found in data_pipeline.ipynb\n",
    "2. Delay modelling\n",
    "    - This section shows the final predictive model of delays used in the project. Feature engineering and other modelling efforst is found in predictive_modelling.ipynb\n",
    "3. Routing algorithm\n",
    "    - This section contains the final routing algorithm used.\n",
    "4. Testing and visualization\n",
    "    - Testing and visualization is the final product of the notebook. Here, one can interact with a UI to the route planner to test the application.\n",
    "    \n",
    "To be able to run the testing of our application you should run all cells in the notebook. In the bottom under the title 'Application', you find the testing interface. Be aware, some queries may take up to 1.5 minutes, but most take around 20 seconds. \n",
    "\n",
    "If something is not working, please contact us at:\n",
    "benjamin.rike@epfl.ch or Slack\n",
    "\n",
    "__Group Gutane:__\n",
    "\n",
    "Andreas Aarrestad\\\n",
    "Benjamin Rike\\\n",
    "Haakon Døssland\\\n",
    "Olav Førland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19040392-5181-4525-b70e-bac07586d56a",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f4964-21bd-4103-be5e-62f1795aee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "from IPython import get_ipython\n",
    "from pyhive import hive\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "pd.set_option(\"display.max_columns\", 50) \n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "hiveaddr = os.environ['HIVE_SERVER2']\n",
    "(hivehost,hiveport) = hiveaddr.split(':')\n",
    "print(\"Operating as: {0}\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3715e-0167-46ae-8ba1-9680f529883b",
   "metadata": {},
   "source": [
    "## Model of public transport infrastructure\n",
    "\n",
    "We start by loading the relevant data from HDFS by using Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713659de-a820-47e5-9adb-f790f34da024",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics\n",
    "# If using Python 3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbca0f-5cf7-4a1b-a243-26c47259ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "# Set up spark session\n",
    "server = 'http://iccluster029.iccluster.epfl.ch:8998'\n",
    "\n",
    "packages = \"\"\"{\"packages\": \"graphframes:graphframes:0.6.0-spark2.3-s_2.11\"}\"\"\"\n",
    "\n",
    "# Set application name as \"<your_gaspar_id>-final_project\"\n",
    "get_ipython().run_cell_magic(\n",
    "    'spark',\n",
    "    line='config', \n",
    "    cell=f\"\"\"{{ \"name\": \"{username}-final_project\", \"executorMemory\": \"4G\", \"executorCores\": 4, \"numExecutors\": 10, \"driverMemory\": \"4G\", \"conf\": {packages}}}\"\"\"\n",
    ")\n",
    "# Send username to spark channel\n",
    "get_ipython().run_line_magic(\n",
    "    \"spark\", \"add -s {0}-final_project -l python -u {1} -k\".format(username, server)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5234bc6-582a-44ef-a873-52a1951ab41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We are using Spark %s' % spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7d35d-944c-427e-b32b-5619768a315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87bc5f-1e8b-4867-9921-a31ee7446faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "# create connection\n",
    "conn = hive.connect(host=hivehost, \n",
    "                    port=hiveport,\n",
    "                    username=username) \n",
    "# create cursor\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced3480-1195-4355-9b5a-3b2dd1d15265",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# Retrieve stops to local\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE IF EXISTS {0}.stops\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    CREATE EXTERNAL TABLE {0}.stops(\n",
    "        stop_id string,\n",
    "        stop_name string,\n",
    "        stop_lat double,\n",
    "        stop_lon double,\n",
    "        distance double\n",
    "    )\n",
    "    STORED AS orc\n",
    "    LOCATION '/group/gutane/stops'\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from {0}.stops \n",
    "\"\"\".format(username)\n",
    "stops = pd.read_sql(query, conn)\n",
    "stops = stops.rename(mapper=lambda x: x.split('.')[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7738ca-3277-46f3-9a72-9de22e36e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# Retrive walking connections to local\n",
    "\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS {0}.walking_connections\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    CREATE EXTERNAL TABLE {0}.walking_connections(\n",
    "        source_id string, \n",
    "        destination_id string, \n",
    "        travel_time int\n",
    "    )\n",
    "    STORED AS ORC\n",
    "    LOCATION '/group/gutane/walking_connections'\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from {0}.walking_connections \n",
    "\"\"\".format(username)\n",
    "walking_connections = pd.read_sql(query, conn)\n",
    "# Fix column names\n",
    "walking_connections = walking_connections.rename(mapper=lambda x: x.split('.')[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c993c-8628-4f76-a030-b44e869c4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "# Retrieve connections to local\n",
    "\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS {0}.connections\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    CREATE EXTERNAL TABLE {0}.connections(\n",
    "        trip_id string,\n",
    "        src_id string, \n",
    "        src_arrival_time string,\n",
    "        src_departure_time string, \n",
    "        dest_id string,\n",
    "        dest_arrival_time string, \n",
    "        dest_departure_time string, \n",
    "        stop_sequence int, \n",
    "        travel_time_from_prev int,\n",
    "        cummulated_travel_time int, \n",
    "        route_short_name string,\n",
    "        route_desc string \n",
    "    )\n",
    "    STORED AS ORC\n",
    "    LOCATION '/group/gutane/connections'\n",
    "\"\"\".format(username)\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    select * from {0}.connections \n",
    "\"\"\".format(username)\n",
    "connections = pd.read_sql(query, conn)\n",
    "connections = connections.rename(mapper=lambda x: x.split('.')[1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250d939-c0aa-48a2-8efc-d8a9e3bf4824",
   "metadata": {},
   "source": [
    "## Network modelling\n",
    "\n",
    "At first, we create a network with stops as nodes and connections and walking connections as edges. The graph is directed as a transport only drive one way. We then inspect whether the graph is strongly connected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1352cdc-140b-448e-90c9-86970e5761df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# defining edges and nodes\n",
    "edges = connections[['src_id', 'dest_id']].to_numpy()\n",
    "edges = edges[edges[:, 1] != None] # Remove edges from end stops\n",
    "walking_edges = walking_connections[['source_id', 'destination_id']].to_numpy()\n",
    "edges = np.vstack([edges, walking_edges])\n",
    "\n",
    "nodes = stops['stop_id']\n",
    "\n",
    "# Creating directed graph\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# checking number of strongly connected components\n",
    "num_connected = nx.number_strongly_connected_components(G)\n",
    "comp = nx.strongly_connected_components(G)\n",
    "largest_comp = max(comp, key=len)\n",
    "percentage_lcc = len(largest_comp) / G.number_of_nodes() * 100\n",
    "\n",
    "print('The largest component has', len(largest_comp), \n",
    "      'nodes', 'accounting for %.2f'% percentage_lcc, '% of the nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418985f9-c11b-47d8-b7ed-d000b8e29708",
   "metadata": {},
   "source": [
    "We filter away stops not in the largest component, as mentioned as a valid approach during the Q&A lecture. This is because the only way to come to these stops is to go through stops outside the 15km radius. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d23184-a88d-4a04-8602-d807b6cf8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# finding the largest component and creating a new subgraph from this\n",
    "Gcc = sorted(nx.strongly_connected_components(G), key=len, reverse=True)\n",
    "G2 =  G.subgraph(Gcc[0])\n",
    "\n",
    "# only keeping connections in G2\n",
    "temp = connections[['src_id', 'dest_id']].to_numpy()\n",
    "connections['keep'] = [G2.has_edge(x[0], x[1]) for x in temp]\n",
    "connections = connections[connections.keep==True]\n",
    "connections.drop('keep', axis=1, inplace=True)\n",
    "\n",
    "# only keeping walking connections in G2\n",
    "temp = walking_connections[['source_id', 'destination_id']].to_numpy()\n",
    "walking_connections['keep'] = [G2.has_edge(x[0], x[1]) for x in temp]\n",
    "walking_connections = walking_connections[walking_connections.keep==True]\n",
    "walking_connections.drop('keep', axis=1, inplace=True)\n",
    "\n",
    "# only keeping stops in G2\n",
    "stops['keep'] = stops['stop_id'].apply(lambda x: G2.has_node(x))\n",
    "stops = stops[stops.keep == True]\n",
    "stops.drop('keep', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05dab95-94e1-4389-8827-d5fcbc77820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "\n",
    "# repating the former calculation and checking whether the whole graph is connected now\n",
    "edges = connections[['src_id', 'dest_id']].to_numpy()\n",
    "edges = edges[edges[:, 1] != None] # Remove edges from end stops\n",
    "walking_edges = walking_connections[['source_id', 'destination_id']].to_numpy()\n",
    "edges = np.vstack([edges, walking_edges])\n",
    "\n",
    "nodes = stops['stop_id']\n",
    "\n",
    "# Create graph\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "num_connected = nx.number_strongly_connected_components(G)\n",
    "comp = nx.strongly_connected_components(G)\n",
    "largest_comp = max(comp, key=len)\n",
    "percentage_lcc = len(largest_comp) / G.number_of_nodes() * 100\n",
    "\n",
    "print('The largest component has', len(largest_comp), \n",
    "      'nodes', 'accounting for %.2f'% percentage_lcc, '% of the nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e365f8-f7f8-4c5a-9d8b-5377dc8d609f",
   "metadata": {},
   "source": [
    "We have achieved a fully strongly connected graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3131d2-5b34-4a54-9011-f9c16bc5c32d",
   "metadata": {},
   "source": [
    "### Analysis of delays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f415a94-e562-4027-a99c-104da4dd4ef0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "As we decided to implement the routing algorithm locally, the inference from the predictive model must also be local. We decided to drop the ml predictive model of two reasons. 1) The model we developed was not much better than baseline. There was almost no correlation between our features and the delay. The only thing that correlated strongly was the departure at the last stop. However, we do not have access to this in real-time and can therefore not use it as a feature. If we were to make our work production-ready, we would accquire this data such that we could use real-time delays to predict future delays. 2) it was dificult to figure out how to move ml weights out of Spark and then run the model. Therefore, we rather decided to fit a probability distribution to the delays and use this as a measure of uncertainty.\n",
    "\n",
    "More information about our approaches to predictive modelling can be found in predictive_modelling.ipynb, but we present the benfits and drawbacks in short here:\n",
    "\n",
    "__Benfits__\n",
    "- Easy and simple\n",
    "- Work directly with a probability distribution which is what we try to model\n",
    "\n",
    "__Drawbacks__\n",
    "- We don't use the predictive power of the other features that we know, so it is not as accuracte as it could be\n",
    "\n",
    "If we have more time, we would use more time creating a better predictive model. It could also be interesting to incoporate real-time data into the modelling as the strongest correlator of delay is previous delay, but this is a large scope.\n",
    "\n",
    "\n",
    "In delays, there are two things we want to model: 1) How likely you are to miss a connections, and 2) How likely you are to not arrive at time at the last stop.\n",
    "\n",
    "Define the following variables:\n",
    "\n",
    "$T_D$ = Actual time of departure\\\n",
    "$T_A$ = Actual time of arrival\\\n",
    "$S_D$ = Scheduled time of departure\\\n",
    "$S_A$ = Scheduled time of arrival\\\n",
    "$A$ = Delay in arrival time\\\n",
    "$D$ = Delay in departure time\\\n",
    "\n",
    "We then want to find for 1):\n",
    "\n",
    "$P({T_D-T_A \\geq 0 })$\n",
    "= $P({S_D + D - S_A + A \\geq 0})$\n",
    "= $P({A-D \\leq S_D - S_A})$\n",
    "\n",
    "By also accounting for transfer time are going to model:\\\n",
    "$P({A-D \\leq S_D - S_A-2})$\n",
    "\n",
    "which corresponds to the CDF of the random variable $A-D$. We must therefore find this distribution.\n",
    "\n",
    "In 2), we only need to model:\n",
    "\n",
    "$P({A \\leq B_T - S_A})$\n",
    "\n",
    "where $B_T$ = the arrival by time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf3bf0-5f95-477c-828f-89d996bbde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data from hdfs\n",
    "sample = spark.read.orc('/group/gutane/processed_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab999577-297a-4f5a-a91d-816fc965ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad9e06-88eb-4f06-b960-696f98c63e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7012680-16f5-4727-a3fb-68fcc5b8f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the predictive modelling notebook we have seen that transport type is what correlates the most with delay\n",
    "# and that train have different delays than bus and tram\n",
    "# therefore, we split in train and other for the model fittings\n",
    "\n",
    "# creating new column for departure delay\n",
    "sample = sample.withColumn('departure_delay', F.col('actual_departure_time').cast('long')-F.col('scheduled_departure_time').cast('long'))\n",
    "sample = sample.filter(sample.departure_delay.isNotNull())\n",
    "\n",
    "#taking a sample of departure and arrival delays\n",
    "delay_train = sample.filter(sample.transport_type=='Zug').select('delay', 'departure_delay', 'transport_type')\n",
    "delay_other = sample.filter(sample.transport_type!='Zug').select('delay', 'departure_delay', 'transport_type')\n",
    "delay_train = delay_train.sample(0.1, seed=41)\n",
    "delay_other = delay_other.sample(0.1, seed=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a8b5b8-94bd-427d-895a-a25d67053de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o delay_train -t df -n 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41fcb0d-8ceb-4153-b741-e0fc9e4d9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o delay_other -t df -n 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75513649-1a8e-40ff-8843-bbfdcaf74680",
   "metadata": {},
   "source": [
    "First, we model the arrival delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd35041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(2,1,figsize=(12,12))\n",
    "sns.histplot(delay_train.delay, ax=ax[0])\n",
    "sns.histplot(delay_other.delay, ax=ax[1])\n",
    "ax[0].set_xlim(-500,1000)\n",
    "ax[0].set_title(\"Delay distribution for trains\")\n",
    "ax[1].set_xlim(-500,1000)\n",
    "ax[1].set_title(\"Delay distribution for other transport types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b735a5-7842-43f5-8e79-08858477206c",
   "metadata": {},
   "source": [
    "We observe that delay follows something that looks like a right-skewed normal distribution. The right tail is longer than the left. We therefore, try estimating the delays with a skewed normal distribution. It does also look like a log-normal distribution, but since it takes on negative values, and there is no left bound, this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b41d39-8a60-4706-9dfd-30a407aba4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "from scipy import stats\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "# fitting the skewed normal distribution\n",
    "a_t, loc_t, scale_t = stats.skewnorm.fit(delay_train.delay)\n",
    "a_o, loc_o, scale_o = stats.skewnorm.fit(delay_other.delay)\n",
    "\n",
    "print(\"Estimated values\")\n",
    "print(\"a                  loc                scale\")\n",
    "print(a_t, loc_t, scale_t)\n",
    "print(a_o, loc_o, scale_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d545c-298c-461f-babe-73a33b9f2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(2,1,figsize=(12,12))\n",
    "sns.histplot(delay_train.delay, ax=ax[0], stat='density', label = \"empirical density\")\n",
    "sns.histplot(delay_other.delay, ax=ax[1], stat='density', label = \"empirical density\")\n",
    "\n",
    "x1 = np.linspace(skewnorm.ppf(0.00001, a_t, loc=loc_t, scale=scale_t),\n",
    "                skewnorm.ppf(0.99999, a_t, loc=loc_t, scale=scale_t), 100)\n",
    "x2 = np.linspace(skewnorm.ppf(0.00001, a_o, loc=loc_o, scale=scale_o),\n",
    "                skewnorm.ppf(0.99999, a_o, loc=loc_o, scale=scale_o), 100)\n",
    "\n",
    "ax[0].plot(x1, skewnorm.pdf(x1, a_t, loc=loc_t, scale=scale_t),\n",
    "       'r-', lw=5, alpha=0.6, label='fitted pdf')\n",
    "ax[1].plot(x2, skewnorm.pdf(x2, a_o, loc=loc_o, scale=scale_o),\n",
    "       'r-', lw=5, alpha=0.6, label='fitted pdf')\n",
    "\n",
    "ax[0].set_xlim(-500,1000)\n",
    "ax[1].set_xlim(-500,1000)\n",
    "\n",
    "ax[0].set_title(\"Distribution of delay and the fitted skewed normal pdf for trains\")\n",
    "ax[1].set_title(\"Distribution of delay and the fitted skewed normal pdf for other transportation\")\n",
    "ax[0].set_xlabel(\"Delay\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "ax[1].set_xlabel(\"Delay\")\n",
    "ax[1].set_ylabel(\"Density\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39a72f-2118-4f73-8ee6-030955edcc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(12,12))\n",
    "sns.ecdfplot(delay_train.delay, ax=ax[0], lw=2, label = \"ECDF\")\n",
    "sns.ecdfplot(delay_other.delay, ax=ax[1], lw=2, label = \"ECDF\")\n",
    "\n",
    "\n",
    "x1 = np.linspace(skewnorm.ppf(0.00001, a_t, loc=loc_t, scale=scale_t),\n",
    "                skewnorm.ppf(0.99999, a_t, loc=loc_t, scale=scale_t), 100)\n",
    "x2 = np.linspace(skewnorm.ppf(0.00001, a_o, loc=loc_o, scale=scale_o),\n",
    "                skewnorm.ppf(0.99999, a_o, loc=loc_o, scale=scale_o), 100)\n",
    "\n",
    "ax[0].plot(x1, skewnorm.cdf(x1, a_t, loc=loc_t, scale=scale_t),\n",
    "       'r-', lw=2, alpha=1, label='fitted CDF')\n",
    "ax[1].plot(x2, skewnorm.cdf(x2, a_o, loc=loc_o, scale=scale_o),\n",
    "       'r-', lw=2, alpha=1, label='fitted CDF')\n",
    "\n",
    "ax[0].set_xlim(skewnorm.ppf(0.00001, a_t, loc=loc_t, scale=scale_t),\n",
    "                skewnorm.ppf(0.99999, a_t, loc=loc_t, scale=scale_t))\n",
    "ax[1].set_xlim(skewnorm.ppf(0.00001, a_t, loc=loc_t, scale=scale_t),\n",
    "                skewnorm.ppf(0.99999, a_t, loc=loc_t, scale=scale_t))\n",
    "\n",
    "ax[0].set_title(\"Empirical cumulative distribution of delay and the fitted skewed normal cdf for trains\")\n",
    "ax[1].set_title(\"Empirical cumulative distribution of delay and the fitted skewed normal cdf for other transportation\")\n",
    "ax[0].set_xlabel(\"Delay\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "ax[1].set_xlabel(\"Delay\")\n",
    "ax[1].set_ylabel(\"Density\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9b5f5-c7ae-4831-b7a4-b9cfe1c6c1b2",
   "metadata": {},
   "source": [
    "We see that the distribution fit the data quite good. It does quite capture the spike around the mean, but otherwise good. Especially, it seems to capture the tails which may be the most important for our task as large delays are more capable of destroying a route plan. However, a weakness in our model is that we will underestimate the number of delays between 50 and 150 seconds for other transportation. Here, there is room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a9ffd-65cf-4757-84f0-8aad6265f8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "print(\"Probability that the delay is smaller than 60 seconds for trains: %.3f\"%stats.skewnorm.cdf(60,a_t, loc_t, scale_t))\n",
    "print(\"Probability that the delay is smaller than 60 seconds for other transport types: %.3f\"%stats.skewnorm.cdf(60,a_o, loc_o, scale_o))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754f6f4-dcc1-4d88-8149-0310a1115b59",
   "metadata": {},
   "source": [
    "Then, we model the difference in arrival and departure delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d10b69d-dbcb-49f0-b0c0-3780e958d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "fig, ax = plt.subplots(2,1,figsize=(12,12))\n",
    "sns.histplot(delay_train.delay-delay_train.departure_delay, ax=ax[0])\n",
    "sns.histplot(delay_other.delay-delay_other.departure_delay, ax=ax[1], bins=100)\n",
    "ax[0].set_xlim(-200,200)\n",
    "ax[0].set_title(\"Arrival minus departure delay distribution for trains\")\n",
    "ax[1].set_xlim(-100,100)\n",
    "ax[1].set_title(\"Arrival minus departure delay distribution for other transport types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02decb1-bfaa-4dd2-9afe-3695ed01caeb",
   "metadata": {},
   "source": [
    "The arrival minus distributions are harder to fit. The above one looks like some kind of Laplace distribution or similar. We tried several modelling approaches below, and found that the Laplace fits best. For the other transport types, it is hard to find a fitting distributions, but we also here fit a Laplace distribution as we assume it should be similar as for trains. This however looks like a bad assumption and something we should attempt fixing, but we unfortunatley ran out of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6d222-c0f5-4e55-84b4-785a00e68537",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "from scipy import stats\n",
    "from scipy.stats import skewnorm, cauchy\n",
    "\n",
    "# fitting the skewed normal distribution\n",
    "a_t_stops, loc_t_stops, scale_t_stops = stats.skewnorm.fit(delay_train.delay-delay_train.departure_delay)\n",
    "a_o_stops, loc_o_stops, scale_o_stops = stats.skewnorm.fit(delay_other.delay-delay_other.departure_delay)\n",
    "\n",
    "print(\"Estimated values\")\n",
    "print(\"a                  loc                scale\")\n",
    "print(a_t, loc_t, scale_t)\n",
    "print(a_o, loc_o, scale_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a20f61-cc8f-41e4-a479-f87f47c5fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "from scipy import stats\n",
    "from scipy.stats import skewnorm, cauchy, norm, laplace\n",
    "\n",
    "# fitting the skewed normal distribution\n",
    "loc_train_laplace, scale_train_laplace = stats.laplace.fit(delay_train.delay-delay_train.departure_delay)\n",
    "loc_other_laplace, scale_other_laplace = stats.laplace.fit(delay_other.delay-delay_other.departure_delay)\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(12,12))\n",
    "sns.histplot(delay_train.delay-delay_train.departure_delay, ax=ax[0], stat='density', label = \"empirical density\")\n",
    "sns.histplot(delay_other.delay-delay_other.departure_delay, ax=ax[1], stat='density', label = \"empirical density\", bins=50)\n",
    "\n",
    "x1 = np.linspace(laplace.ppf(0.00001, loc_train_laplace, scale_train_laplace),\n",
    "                laplace.ppf(0.99999,loc_train_laplace, scale_train_laplace), 100)\n",
    "x2 = np.linspace(laplace.ppf(0.00001, loc_other_laplace, scale_other_laplace),\n",
    "                laplace.ppf(0.99999,  loc_other_laplace, scale_other_laplace), 100)\n",
    "\n",
    "ax[0].plot(x1, laplace.pdf(x1, loc_train_laplace, scale_train_laplace),\n",
    "       'r-', lw=5, alpha=0.6, label='fitted pdf')\n",
    "ax[1].plot(x2, laplace.pdf(x2,  loc_other_laplace, scale_other_laplace),\n",
    "       'r-', lw=5, alpha=0.6, label='fitted pdf')\n",
    "\n",
    "ax[0].set_xlim(-200,200)\n",
    "ax[1].set_xlim(-200,200)\n",
    "\n",
    "ax[0].set_title(\"Distribution of delay differences and the fitted laplace pdf for trains\")\n",
    "ax[1].set_title(\"Distribution of delay differences and the fitted laplace pdf for other transportation\")\n",
    "ax[0].set_xlabel(\"Delay\")\n",
    "ax[0].set_ylabel(\"Density\")\n",
    "ax[1].set_xlabel(\"Delay\")\n",
    "ax[1].set_ylabel(\"Density\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47198290-7e3f-4676-b602-57c4189ef71d",
   "metadata": {},
   "source": [
    "The Laplace distribution does an ok job of fitting the difference for trains, but not very much for other transportation. This is a weakness of our model, and something we would like to work more on, but we ran out of time and prioritize improving the routing algorithm. Further work should try developing a model that uses more of the available information to model the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a895d83-5add-49de-8b71-89aeefcaa452",
   "metadata": {},
   "source": [
    "## Route planning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc775b-f4f5-4fc9-8dd0-b2ae55ba3516",
   "metadata": {},
   "source": [
    "#### Network \n",
    "As the routing requires a customizable network, we decided to code it ourselves from scratch. Each node in the network represents a stop and each edge is a time dependant direct route between two stops. This is implemented by storing a table of all routes in each node to its adjacent nodes indexed by the adjacent node itself. This ensures fast lookup during search, but makes for a larger overhead during graph creation. \n",
    "\n",
    "#### Search \n",
    "When the graph has been built, there's a range of different flags and values that are set throughout the search. These dynamic variables are initialized with default values during each run, while the static variables remain constant. \n",
    "\n",
    "#### Optimality\n",
    "As each stop has a physical location, we decided to use a customized version of the best-first search algorithm A*. It is an extension of Dijkstra's algorithm where the functionality for picking the next node to traverse is also based on an estimate of the distance to the destination. This heuristic function is in our case the euclidean distance, which will always be less or equal to the actual shortest path to the destination. As such, the heuristic is admissable and will therefore ensure optimality. \n",
    "\n",
    "The choosing of the next node to traverse is implemented by the use of a minheap with an index given by the sum of the elapsed time and the distance heuristic, while the corresponding value is a reference to the node.\n",
    "\n",
    "#### Time variance\n",
    "As the edge cost in our case between two nodes is not static, and based on the elapsed time to the node, we have to modify the algorithm to do a lookup of the edge cost during each new route evaluation. This makes our algorithm a bit slower, but is not substantial because of the table distribution during graph population.\n",
    "\n",
    "#### Uncertainty\n",
    "When we are modelling the fastest route at a certain confidence level, the delay distribution is essential. To simplify task, we have assumed that there is no correlation between delays. (a simplification that we have seen in predictive_modelling.ipynb to be very wrong) . We calculate uncertainties every time the user is going to change transport. That means that we calcualte the probability that he is able to reach the next departure. This is modelled by calculating the CDF-value for the difference in scheduled arrival time and scheduled departure time.\n",
    "\n",
    "We also calculate the uncertainty at the end stop for the arrival time. Here we also assume no correlation between delays such that this is just the cdf of the difference of arrival_by_time and scheduled_arrival_time. We then cumulativley multiply the probabilities for each route and discard a route if the probability is lower than the maximum \n",
    "\n",
    "#### Other heuristics and assumptions\n",
    "- To disincentivize changing transportation too often, a two minute transfer time is added.  \n",
    "- To choose to walk a distance, the walk must be 2 minutes faster than taking a transport. We chose this as it fits with what we would wish in real life. It is worth waiting 2 minutes if we otherwise must walk\n",
    "- We don't account for switching route in the case of delay. Once a route is planned, we expect the user to follow it.\n",
    "- The algorithm do not take into account the consequences of missing one connection vs. another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eaca89-bc22-4fea-a027-8246de30116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import heapq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ab598-3c46-4f5f-b384-8e96a935ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# removing nans and some formatting\n",
    "route_connections = connections[connections['dest_id'].notna()]\n",
    "for i in ['src_arrival_time','src_departure_time','dest_arrival_time','dest_departure_time']:\n",
    "    route_connections.loc[i,:] = route_connections[i].apply(lambda d : pd.Timestamp(d))\n",
    "    \n",
    "# smaller sample while testing    \n",
    "route_connections = route_connections#.head(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d46a1-e2c4-4fb3-a9af-0606c62e5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local \n",
    "labels = ['trip_id', 'src_id', 'src_arrival_time', 'src_departure_time', \n",
    "          'dest_id', 'dest_arrival_time', 'dest_departure_time', 'stop_sequence', \n",
    "          'travel_time_from_prev', 'cummulated_travel_time', 'route_short_name', \n",
    "          'route_desc', 'cum_confidence', 'arrival_confidence']\n",
    "\n",
    "# Takes a column name and returns the corresponding index, in the \n",
    "# order the columns are in the dataframes\n",
    "def get_index(column):\n",
    "    label_map = \\\n",
    "        {c:i for i, c in enumerate(labels)}\n",
    "    return label_map[column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5363e2c-1464-4f83-b9da-1ea5a4a78050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "class Node:\n",
    "    def __init__(self, stop_id, stop_name, lat, lon):\n",
    "        # STATIC PARAMETERS\n",
    "        self.stop_id = stop_id\n",
    "        self.stop_name = stop_name\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        self.routes = {} # destination_stop_id -> table[tripID, departure_timestamp, arrival_timestamp, route_short_name]\n",
    "        self.walking_connections = {} # destination_stop_id -> time\n",
    "         \n",
    "        # DYNAMIC PARAMETERS\n",
    "        self.intialize_dynamic_parameters()\n",
    "        \n",
    "    def intialize_dynamic_parameters(self):\n",
    "        self.parent = None\n",
    "        self.origin_route = None\n",
    "        self.has_gained_optimum = False\n",
    "        self.is_under_consideration = False\n",
    "        self.elapsed_time = float('inf')\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.stop_id < other.stop_id\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return self.stop_id <= other.stop_id\n",
    "    \n",
    "    def add_route_timetable(self, adjacent_node_id, timetable):\n",
    "        self.routes[adjacent_node_id] = timetable \n",
    "    \n",
    "    def add_walking_connection(self, adjacent_node_id, walking_time):\n",
    "        self.walking_connections[adjacent_node_id] = walking_time\n",
    "    \n",
    "    def calculate_confidence(self, trips):\n",
    "        \"\"\"Calculating the confidence for being in time for the departure time at the next stop.\n",
    "        Currently, only accounts for the delay in arrival time, not in departure time. This leads to too conservative estimates.\"\"\"\n",
    "        \n",
    "        #TODO: Add suport for departure modelling too?\n",
    "        # If so, we need to change docstring too.\n",
    "        # extracting the transport vehicle of every trip\n",
    "        transport = trips[:, get_index('route_desc')]\n",
    "        \n",
    "        # assinging 1 in confidence if there is no previous route\n",
    "        # this is because we assume one is not too late to the first departure\n",
    "        if self.origin_route == None:\n",
    "            confidence = np.asarray([1 for element in transport])\n",
    "            return confidence\n",
    "        \n",
    "        \n",
    "        if isinstance(self.origin_route, np.ndarray):\n",
    "            # calculating the time between scheduled arrival and departure\n",
    "            arrival_time = self.origin_route[-1].get('dest_arrival_time')\n",
    "            if isinstance(arival_time, str):\n",
    "                diff_time = (trips[:,get_index('src_departure_time')] -\n",
    "                         pd.Timestamp(arrival_time).to_pydatetime())\n",
    "            else:\n",
    "                diff_time = (trips[:,get_index('src_departure_time')] -\n",
    "                         (arrival_time).to_pydatetime())\n",
    "                \n",
    "            # accounting for transfer time\n",
    "            diff_time = diff_time - pd.Timedelta(2)\n",
    "            \n",
    "            # calculating the confidence by using the estimated cdf\n",
    "            f = lambda x: x.seconds\n",
    "            vf = np.vectorize(f)\n",
    "            confidence = np.where(transport==\"Zug\",\n",
    "                                  stats.laplace.cdf(vf(diff_time), loc_train_laplace, scale_train_laplace),\n",
    "                                  stats.laplace.cdf(vf(diff_time), loc_train_laplace, scale_train_laplace)\n",
    "                                 )\n",
    "\n",
    "            # only using the confidence if one switches route\n",
    "            # this is because one cannot be too late for as bus one already is on\n",
    "            confidence = np.where(trips[:, get_index('route_short_name')]!=\n",
    "                                  self.origin_route[-1].get('route_short_name'),\n",
    "                                  confidence,\n",
    "                                  1)\n",
    "        else:\n",
    "            # same as in if, just that origin_route isn't a list\n",
    "            arrival_time = self.origin_route.get('dest_arrival_time')\n",
    "            if isinstance(arrival_time, str):\n",
    "                diff_time = (trips[:,get_index('src_departure_time')] -\n",
    "                         pd.Timestamp(arrival_time).to_pydatetime())\n",
    "            else:\n",
    "                diff_time = (trips[:,get_index('src_departure_time')] -\n",
    "                         (arrival_time).to_pydatetime())\n",
    "                \n",
    "            diff_time = diff_time - pd.Timedelta(2)\n",
    "            \n",
    "            f = lambda x: x.seconds\n",
    "            vf = np.vectorize(f)\n",
    "            \n",
    "            confidence = np.where(transport==\"Zug\",\n",
    "                                  stats.laplace.cdf(vf(diff_time),loc_train_laplace, scale_train_laplace),\n",
    "                                  stats.laplace.cdf(vf(diff_time), loc_train_laplace, scale_train_laplace)\n",
    "                                 )\n",
    "                                 \n",
    "            confidence = np.where(trips[:, get_index('route_short_name')]!=\n",
    "                                  self.origin_route.get('route_short_name'),\n",
    "                                  confidence,\n",
    "                                  1)\n",
    "        return confidence\n",
    "    \n",
    "    def calc_final_conf(self, trips, by_time):\n",
    "        \"\"\"Calculates the confidence with which the trip reaches the destination by the \n",
    "        by_time. Only looks on the trip from the next last stop to the last stop\n",
    "        as we assume i.i.d. delays which do not propogate\"\"\"\n",
    "        transport = trips[:, get_index('route_desc')]\n",
    "        diff_time = ((trips[:,get_index('dest_arrival_time')]).astype('datetime64[s]') - \n",
    "                     np.datetime64(pd.Timestamp(by_time)))\n",
    "        diff_time = np.asarray([pd.Timedelta(element).seconds for element in diff_time])\n",
    "        confidence = np.where(transport == \"Zug\", \n",
    "                             stats.skewnorm.cdf((diff_time), a_t, loc_t, scale_t),\n",
    "                             stats.skewnorm.cdf((diff_time), a_o, loc_o, scale_o))\n",
    "        return confidence\n",
    "        \n",
    "        \n",
    "    def wait(self, transport):\n",
    "        # returns the media wait time at a stop while being too late for a given transport type\n",
    "        return [pd.Timedelta(seconds = 48) if element==\"Zug\" else pd.Timedelta(12) for element in transport]\n",
    "    \n",
    "    def previous_confidence(self):\n",
    "        # retrieving the previous cumulative confidence by looking up in self.origin_route\n",
    "        if self.origin_route == None:\n",
    "            cum_conf_previous = 1\n",
    "        else:\n",
    "            if isinstance(self.origin_route, np.ndarray):\n",
    "                cum_conf_previous = self.origin_route[-1].get('cum_confidence')\n",
    "            else:\n",
    "                cum_conf_previous = self.origin_route.get('cum_confidence')\n",
    "        return cum_conf_previous\n",
    "    \n",
    "    def get_optimal_route(self, adjacent_node_id, departure_timestamp, confidence, destination, by_time):\n",
    "        \"\"\"Returns the optimal route between two stops\"\"\"\n",
    "        # flag telling if the route is to destination or not\n",
    "        # will only calculate arrival delay if this is true\n",
    "        # in the other cases, we only check if the delay makes us miss a connection\n",
    "        # we do it this way as we assume to correlation betwen delays\n",
    "        # then, arrival delay is only the delay between the next last and the last stop\n",
    "        to_final = False\n",
    "        if destination == adjacent_node_id:\n",
    "            to_final = True\n",
    "            \n",
    "        current_time_timestamp = (pd.Timestamp(departure_timestamp) + pd.Timedelta(seconds=self.elapsed_time)).strftime('%Y-%m-%d %X')\n",
    "        time = pd.Timestamp(current_time_timestamp)\n",
    "        transfer_time = pd.Timedelta(minutes=2)\n",
    "        found_connection = False\n",
    "\n",
    "        \n",
    "        # iterating over adjacent nodes\n",
    "        if adjacent_node_id in self.routes.keys():\n",
    "            \n",
    "            \n",
    "            found_connection = True\n",
    "            routes_to_adjacent = self.routes[adjacent_node_id]\n",
    "            \n",
    "            # converting time strings to datetime\n",
    "            routes_to_adjacent[:, get_index('src_departure_time')] = routes_to_adjacent[:, get_index('src_departure_time')].astype('datetime64[s]')\n",
    "            routes_to_adjacent[:, get_index('src_arrival_time')] = routes_to_adjacent[:, get_index('src_arrival_time')].astype('datetime64[s]')\n",
    "            \n",
    "            \n",
    "            if self.origin_route == None:\n",
    "                # filtering out trips which starts too late\n",
    "                available_trips = routes_to_adjacent[routes_to_adjacent[:, get_index('src_departure_time')] >= time]\n",
    "            else:\n",
    "                # filtering out trips which starts too late compared to time + possible transfer time\n",
    "                available_trips = (routes_to_adjacent[(routes_to_adjacent[:, get_index('src_departure_time')] >= time+transfer_time)  |\n",
    "                                                ((routes_to_adjacent[:, get_index('src_departure_time')] >= time) &\n",
    "                                                 (routes_to_adjacent[:, get_index('route_short_name')] == self.origin_route.get('route_short_name')))]\n",
    "                              )\n",
    "            # if there is available trips\n",
    "            if available_trips.size > 0:\n",
    "                \n",
    "                cum_conf_previous = self.previous_confidence()\n",
    "                # heuristic for speed purposes\n",
    "                # only calculating confidences for 10 fastest trips\n",
    "                k = 5\n",
    "                if available_trips.shape[0]>=k:\n",
    "                    kth_smallest = np.partition(available_trips[:, get_index('dest_arrival_time')], k-1)[k-1]\n",
    "                    available_trips = available_trips[available_trips[:, get_index('dest_arrival_time')] <= \n",
    "                                                   kth_smallest]\n",
    "                # for trip in available_trips, calculate confidence that you will reach the departure\n",
    "                current_confidence = self.calculate_confidence(available_trips) #calculate confidence for every element in available_trips\n",
    "                #current_confidence = np.asarray([1 for element in range(available_trips.shape[0])])\n",
    "                # calculating new cumulative confidence as previous times this departure's\n",
    "                cum_confidence = cum_conf_previous*current_confidence\n",
    "                # stacking cumulative confidence to available trips\n",
    "                available_trips = np.hstack([available_trips, np.expand_dims(cum_confidence, 1)])\n",
    "                # keeping trips which still fullfils the confidence limit\n",
    "\n",
    "\n",
    "                available_trips = available_trips[available_trips[:, -1] >=\n",
    "                                                 confidence]\n",
    "                \n",
    "                # finally, if the trip is to the destination node\n",
    "                # we check that we reach it by the necessary arrival time\n",
    "                if to_final:\n",
    "                    if available_trips.shape[0]>=k:\n",
    "                        kth_smallest = np.partition(available_trips[:, get_index('dest_arrival_time')], k-1)[k-1]\n",
    "                        available_trips = available_trips[available_trips[:, get_index('dest_arrival_time')] <= \n",
    "                                                       kth_smallest]\n",
    "                    final_confidence = self.calc_final_conf(available_trips, by_time)\n",
    "                    available_trips[:,-1] = available_trips[:,-1]*final_confidence\n",
    "                    available_trips = available_trips[final_confidence >=\n",
    "                                                 confidence]\n",
    "                # checking if there still is available trips\n",
    "                if available_trips.size > 0:\n",
    "                    # calculating the trip which reaches the destination the earliest\n",
    "                    optimal_trip = available_trips[available_trips[:, get_index('dest_arrival_time')] == \n",
    "                                                   available_trips[:, get_index('dest_arrival_time')].min()]\n",
    "                    \n",
    "                else:\n",
    "                    found_connection = False\n",
    "            else:\n",
    "                found_connection = False\n",
    "                # calculating the previous cumulative confidence\n",
    "                cum_conf_previous = self.previous_confidence()\n",
    "        else:\n",
    "            cum_conf_previous = self.previous_confidence()\n",
    "        if not found_connection:\n",
    "            optimal_trip = np.asarray([[]])\n",
    "            \n",
    "        # no connections\n",
    "        if optimal_trip.size == 0 and (adjacent_node_id not in self.walking_connections.keys()):\n",
    "            return False\n",
    "            \n",
    "        walk = np.inf   \n",
    "        # checks walking connections\n",
    "        if adjacent_node_id in self.walking_connections.keys():\n",
    "            walk = self.walking_connections[adjacent_node_id]\n",
    "            walk_arrival_time = time + pd.Timedelta(seconds=walk)\n",
    "            # Pseudo-correct dictionary for walking times -> follows the same format as a trip connection\n",
    "            walking_trip = {'trip_id': \"\", 'src_id': self.stop_id, 'src_arrival_time': time, 'src_departure_time': time, \n",
    "                      'dest_id': adjacent_node_id, 'dest_arrival_time': walk_arrival_time, 'dest_departure_time': walk_arrival_time,\n",
    "                      'stop_sequence': 0, 'travel_time_from_prev': 0, 'cummulated_travel_time': 0, 'route_short_name': 'Walk', \n",
    "                      'route_desc': 'Walk', 'cum_confidence':cum_conf_previous}\n",
    "            \n",
    "            # if no transport trip, we return the walk\n",
    "            if optimal_trip.size == 0:\n",
    "                return walking_trip, walk\n",
    "            \n",
    "        if optimal_trip.size > 0: \n",
    "            trip_arrival_timestamp = optimal_trip[:, get_index('dest_arrival_time')][0]\n",
    "            elapsed_time = pd.Timedelta(pd.Timestamp(trip_arrival_timestamp) - time).seconds\n",
    "            \n",
    "            # if no walking connections, return shortest transport\n",
    "            if not self.walking_connections:\n",
    "                res = {l: optimal_trip[-1, :][i] for i, l in enumerate(labels[:optimal_trip.shape[1]])}\n",
    "                return res, elapsed_time\n",
    "        \n",
    "        # if walk is 2 minute faster than transport --> walk\n",
    "        if walk + 120 < elapsed_time:\n",
    "            return walking_trip, walk\n",
    "        \n",
    "        if True:\n",
    "            res = {l: optimal_trip[-1, :][i] for i, l in enumerate(labels[:optimal_trip.shape[1]])}\n",
    "            return res, elapsed_time\n",
    "\n",
    "    \n",
    "    def get_all_successor_stop_ids(self):\n",
    "        if self.routes.keys():\n",
    "            return self.routes.keys()\n",
    "        return self.walking_connections.keys()\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "97311cb9-8248-4aa1-85e0-f1d2e7c566bc",
   "metadata": {},
   "source": [
    "trip_id                   949.TA.26-5-j20-1.25.R\n",
    "src_id                                   8591329\n",
    "src_arrival_time             2022-05-26 11:23:00\n",
    "src_departure_time           2022-05-26 11:23:00\n",
    "dest_id                                  8591366\n",
    "dest_arrival_time          2022-05-26 11:24:00.0\n",
    "dest_departure_time        2022-05-26 11:24:00.0\n",
    "stop_sequence                                2.0\n",
    "travel_time_from_prev                       60.0\n",
    "cummulated_travel_time                      60.0\n",
    "route_short_name                               5\n",
    "route_desc                                  Tram\n",
    "conf_departure               2022-05-26 11:23:00\n",
    "max_departure                2022-05-26 11:23:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9ab9b-2a50-49ec-bd48-5564d32f566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "from datetime import datetime\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        # contains all the stops in the network. edges are stored in the nodes.\n",
    "        self.nodes = {}\n",
    "\n",
    "    # add new nodes and their routes to other nodes\n",
    "    def populate(self, stops, connections, walking_connections):\n",
    "        \"\"\"\n",
    "        Populate each node with its connecting routes \n",
    "        @param stops: df with stop_id: string, stop_name: string, stop_lat: double, stop_lon: double\n",
    "        @param connections: df with trip_id: string, arrival_time: timestamp, departure_time: timestamp, source_id: string, destination_id: string\n",
    "        \"\"\"\n",
    "        for index, stop in stops.iterrows():\n",
    "            node = Node(stop['stop_id'], stop['stop_name'], stop['stop_lat'], stop['stop_lon'])\n",
    "            trips_from_node = connections[connections['src_id'] == stop['stop_id']]\n",
    "            destinations_from_node = trips_from_node['dest_id'].unique()\n",
    "            for destination in destinations_from_node:\n",
    "                timetable = trips_from_node[trips_from_node['dest_id'] == destination].to_numpy()\n",
    "                \n",
    "                node.add_route_timetable(destination, timetable)\n",
    "            self.nodes[stop['stop_id']] = node \n",
    "            connections_from_stop = walking_connections[walking_connections['source_id'] == stop['stop_id']]\n",
    "            for _, connection in connections_from_stop.iterrows():\n",
    "                node.add_walking_connection(connection.destination_id, connection.travel_time)\n",
    "                \n",
    "\n",
    "    def find_shortest_path(self, departing_stop_id, destination_stop_id, departure_timestamp, by_time, confidence = 0.9):\n",
    "        \"\"\"\n",
    "        Finds shortest path with a time variant A* algorithm implementation \n",
    "        @param: departing_stop_id: stop id of the start position, string\n",
    "        @param: destination_stop_id: stop id of the stop position, string\n",
    "        @param: departure_timestamp: timestamp of trip initiation, string\n",
    "        \"\"\"\n",
    "        # reset dynamic variables of all nodes\n",
    "        for _, node in self.nodes.items():\n",
    "            node.intialize_dynamic_parameters()\n",
    "        \n",
    "        # initialize departure node parameters\n",
    "        departing_node = self.get_node(departing_stop_id)\n",
    "        departing_node.is_under_consideration = True # halvveis redundant hotfix\n",
    "        departing_node.elapsed_time = 0\n",
    "        departure_time = pd.Timestamp(departure_timestamp)\n",
    "        \n",
    "        # initialize priority queue based on a function of the path distance and the heuristic distance\n",
    "        nodes_under_consideration = [(0, departing_node)]\n",
    "        heapq.heapify(nodes_under_consideration) \n",
    "        \n",
    "        while len(nodes_under_consideration) > 0:\n",
    "            (distance, current_node) = heapq.heappop(nodes_under_consideration) # unvisited node with lowest h(x) + g(x) \n",
    "            current_node.has_gained_optimum = True\n",
    "            #print(f\"evaluating stop {current_node.stop_id}\")\n",
    "            if current_node.stop_id == destination_stop_id:\n",
    "                path = [] \n",
    "                while current_node.parent:\n",
    "                    path.append({\n",
    "                        \"parent_stop_name\":current_node.parent.stop_name,\n",
    "                        \"current_stop_name\":current_node.stop_name,\n",
    "                        \"route\":current_node.origin_route,\n",
    "                        \"successor_lat\": current_node.lat,\n",
    "                        \"successor_lon\": current_node.lon\n",
    "                    })\n",
    "                    current_node = current_node.parent\n",
    "                return path[::-1] \n",
    "            \n",
    "            # looping over all adjacent nodes\n",
    "            successors_stop_ids = current_node.get_all_successor_stop_ids()\n",
    "            for successor_stop_id in successors_stop_ids:\n",
    "                successor_node = self.get_node(successor_stop_id)\n",
    "                if successor_node.has_gained_optimum:\n",
    "                    continue\n",
    "                \n",
    "                # evaluate alternative route to successor node through current node\n",
    "                optimal_route = current_node.get_optimal_route(successor_node.stop_id, departure_time,\n",
    "                                                               confidence, destination_stop_id, by_time)\n",
    "                \n",
    "                \n",
    "                # trash hotfix of instance where there's no more routes for the day\n",
    "                if not optimal_route or isinstance(optimal_route[1], float):\n",
    "                    continue\n",
    "                    \n",
    "                # calculating the elapsed time to each adjacent node through the current node \n",
    "                # and updating the adjacent node's path if it's quicker\n",
    "                (optimal_trip_proposal, optimal_elapsed_time_proposal) = optimal_route\n",
    "                optimal_total_elapsed_time_proposal = current_node.elapsed_time + optimal_elapsed_time_proposal\n",
    "                if successor_node.is_under_consideration:\n",
    "                    if optimal_total_elapsed_time_proposal < successor_node.elapsed_time:\n",
    "                        successor_node.elapsed_time = optimal_total_elapsed_time_proposal\n",
    "                        successor_node.origin_route = optimal_trip_proposal\n",
    "                        successor_node.parent = current_node\n",
    "\n",
    "                else:\n",
    "                    successor_node.elapsed_time = optimal_total_elapsed_time_proposal\n",
    "                    successor_node.origin_route = optimal_trip_proposal\n",
    "                    successor_node.parent = current_node\n",
    "                    distance_heuristic = self.distance_heuristic(successor_node.stop_id, destination_stop_id)\n",
    "                    heapq.heappush(nodes_under_consideration, (successor_node.elapsed_time + distance_heuristic, successor_node))\n",
    "        return 'no_path'\n",
    "    \n",
    "    \n",
    "    def get_node(self, stop_id):\n",
    "        return self.nodes.get(stop_id)\n",
    "    \n",
    "    def distance_heuristic(self, stop_id, target_stop_id):\n",
    "        \"\"\"Finding the euclidean distance between a source stop and a target stop, This is used\n",
    "        as a heuristic to speed up the A* algorithm\"\"\"\n",
    "        node = self.get_node(stop_id)\n",
    "        target_node = self.get_node(target_stop_id)\n",
    "        alpha = 1\n",
    "        distance = alpha*np.sqrt((node.lat - target_node.lat)**2 + (node.lon - target_node.lon)**2)\n",
    "        return distance\n",
    "    \n",
    "    def get_connection_transfer_time(self, trip1, trip2):\n",
    "        if trip1 is trip2:\n",
    "            return 0\n",
    "        return 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def pretty_print_route(path):\n",
    "        def unit_to_text(quantity, unit):\n",
    "            ret = str(quantity)+' '+ unit \n",
    "            if quantity != 1:\n",
    "                ret += 's'\n",
    "                \n",
    "            return ret\n",
    "        if path=='no_path':\n",
    "            return False\n",
    "        print(f\"Trip No.{''.ljust(2)} Route{''.ljust(23)} Line{''.ljust(3)} Mode{''.ljust(4)} Departure time{''.ljust(7)} Departure stop {''.ljust(23)} Arrival time {''.ljust(8)} Arrival stop\")\n",
    "        print(f\"{''.join(['-' for i in range(150)])}\")\n",
    "        for i, row in enumerate(path):\n",
    "            if i>=10:\n",
    "                break\n",
    "            print(f\"{str(i).ljust(10)} {row['route']['trip_id'].ljust(28)} {row['route']['route_short_name'].ljust(7)} {row['route']['route_desc'].ljust(7)}  {str(row['route']['src_departure_time']).ljust(21)} {row['parent_stop_name'].ljust(35)}->  {str(row['route']['dest_arrival_time']).ljust(21)} {row['current_stop_name']}\")\n",
    "        print(f\"{''.join(['-' for i in range(150)])}\")\n",
    "        \n",
    "        elapsed_time = pd.Timestamp(path[-1]['route']['dest_arrival_time']).to_pydatetime() - pd.Timestamp(path[0]['route']['src_departure_time']).to_pydatetime()\n",
    "        hours, remainder = divmod(elapsed_time.seconds, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        print(f\"Total travel time: {unit_to_text(hours, 'hour')}, {unit_to_text(minutes, 'minute')} and {unit_to_text(seconds, 'second')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c463e75-f4a5-475b-af67-6f16d1a33d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# some helpers\n",
    "def get_num_switch(sp):\n",
    "    \"\"\"Returns the number of switches for a shortest path\"\"\"\n",
    "    count = 0\n",
    "    for i, element in enumerate(sp):\n",
    "        route = element.get('route')\n",
    "        if i!=0:\n",
    "            if route.get('route_short_name') != sp[i-1].get('route').get('route_short_name'):\n",
    "                count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c26209f-18be-4b7b-9051-9bf87b70ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local    \n",
    "# instantiate network\n",
    "network = Network()\n",
    "network.populate(stops, route_connections, walking_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f0c7f-9f9e-4c15-9729-0acf1852d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "source = '8591329'\n",
    "destination = '8591220'\n",
    "departure_time = '2022-05-26 10:24:00'\n",
    "arrival_by = '2022-05-26 10:44:00' # this is redudant in this algorithm, but important for the final algorithm below\n",
    "confidence = 0.7\n",
    "# Saalsporthalle -> Kantonsschule, skal fungere helt fint siden de ligger på samme rute\n",
    "%time sp = network.find_shortest_path(source, destination, departure_time, arrival_by, confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff9051-acae-4ead-98da-66d0a26f5880",
   "metadata": {},
   "source": [
    "The algorithm above, finds the fastest route from source to destination from a given time, but the query in the application is on arrival time. The query_routes method below takes care of this. The method works like a variant of binary search. We initialize by searching inside the hour before arrival by using binary search. For every route that meets the criteria, we save the route and continue the binary search until a route is found. This way, we return route options but guarantee to find the optimal one. If there is no route inside the hour, we search from 1 hour to 2 hours, then 2 hours to 4 hours, etc. This method gave a 5-fold speed increase compared to the naive implementation we first created which decremented time by one per search.\n",
    "\n",
    "We realize that this algorithm is not the most effective for the routing. Instead, we could implement a reverse version of the A* where we start at arrival time from the destination and try to find departure node and departure time. This way, we would reduce the number of routing algorithms calls we do. We kept the A* propoagting forward as we initially thought we had to for the uncertainty modelling to work properly. Later, we understood that this was unnecessary as we would not use delay at previous stops as a predictior for delay at the current stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d68dae-c329-4476-8a63-1f887db23ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import datetime\n",
    "\n",
    "def query_routes(source='8591329', destination='8591220', by_time='2022-05-26 10:45:00', confidence=0.9):\n",
    "    \n",
    "    if (source not in stops.stop_id.values) or (destination not in stops.stop_id.values):\n",
    "        print('Invalid stops')\n",
    "        return False\n",
    "    \n",
    "    by_time = pd.Timestamp(by_time)\n",
    "    routes = []\n",
    "    confidence = float(confidence)\n",
    "    \n",
    "    # starting by looking for routes inside the hour\n",
    "    max_time = 60\n",
    "    min_time = 0\n",
    "\n",
    "    # intitating the time difference\n",
    "    delta_time = np.inf\n",
    "    \n",
    "    # keeping track  of where we have searched\n",
    "    delta_times = []\n",
    "    \n",
    "    # running until optimal route found\n",
    "    while True:\n",
    "        \n",
    "        # doubling the search space if we haven't found any routes\n",
    "        if delta_time == max_time:\n",
    "            max_time = max_time*2\n",
    "        \n",
    "        # how long back in time we search in this iteration\n",
    "        delta_time = pd.Timedelta(minutes = int((max_time+min_time)/2))\n",
    "        \n",
    "        # if we already have used this delta_time, the search is completed.\n",
    "        if delta_time in delta_times:\n",
    "            break\n",
    "        delta_times.append(delta_time)\n",
    "        \n",
    "        time_n = by_time - delta_time # the departure time to search from\n",
    "        # finding shortest path\n",
    "        sp = network.find_shortest_path(source, destination, str(time_n), str(by_time), confidence)\n",
    "        # if no path, increase the time difference\n",
    "        if sp=='no_path':\n",
    "            min_time = delta_time.seconds//60\n",
    "            continue\n",
    "        arrival_time = pd.Timestamp(sp[-1].get('route').get('dest_arrival_time'))\n",
    "        \n",
    "        # if the path does not arrive fast enough, increasee time difference\n",
    "        if arrival_time > by_time:\n",
    "            min_time = delta_time.seconds//60 \n",
    "            \n",
    "        # if one finds a route, decrease time difference and see if we can find a faster route\n",
    "        elif arrival_time <= by_time:\n",
    "            max_time = delta_time.seconds//60\n",
    "            if sp not in routes:\n",
    "                routes.append(sp)\n",
    "                \n",
    "    return routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c7f03-bdd2-4757-97cc-275e0650cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# testing the algorithm on a deafult route\n",
    "%time routes = query_routes()\n",
    "\n",
    "# some data manipulation for cleaner print\n",
    "route_times = [route[0].get('route').get('src_arrival_time') for route in routes]\n",
    "route_indices = np.flip(np.argsort(route_times))\n",
    "routes = list(np.asarray(routes)[route_indices])\n",
    "for i, sp in enumerate(routes):\n",
    "    sp_start = sp[0].get('route').get('src_departure_time')\n",
    "    sp_end = sp[-1].get('route').get('dest_arrival_time')\n",
    "    print(\"%dth alternative:     Departure: %s.     Arrival: %s     Switches: %d\"%(i+1, sp_start, sp_end, get_num_switch(sp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c22a73-2d9d-4e32-83f3-8a2335811602",
   "metadata": {},
   "source": [
    "## Test of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6962cb-8ffd-482d-95ea-a6e80d6a573a",
   "metadata": {},
   "source": [
    "In this section, we will show the results of some tests, and provide an interface to play with the algorithm. But first, we define some functions for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadc68e-865b-4c53-a222-df59483c45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "#create widgets to be used for visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from ipywidgets import interactive, widgets, interact, Button, Text, HTML, VBox, HBox, Select, Layout\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "search_button = Button(description=\"Search Route\")\n",
    "\n",
    "source=Text(\n",
    "        value='Zürich, Saalsporthalle',\n",
    "        placeholder='Source destination',\n",
    "        description = 'Origin:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "destination=Text(\n",
    "    value='Zürich, Kantonsschule',\n",
    "    placeholder='End destination',\n",
    "    description='Destination:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "time=Text(\n",
    "    value='2022-05-26 10:45:00',\n",
    "    placeholder='00:00',\n",
    "    description='Arrival time:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "certainty=Text(\n",
    "    value='0.8',\n",
    "    placeholder='0.8',\n",
    "    description='Confidence level ([0,1)):',\n",
    "    disabled=False,\n",
    "    style = {'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "arrow=HTML(\n",
    "    value=\"<b>&rarr;</b>\",\n",
    ")\n",
    "\n",
    "        \n",
    "hcontainer = HBox(children=[source, arrow, destination])\n",
    "hcontainer2 = HBox(children=[time, certainty])\n",
    "vcontainer = VBox(children=[hcontainer, hcontainer2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b775904-3ee5-49f9-b9d6-d7aac0c571e0",
   "metadata": {},
   "source": [
    "### Helping methods to display information\n",
    "The methods below are used when ploting the trips found by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c59d93-9153-4401-84c0-1b83c09b906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "#Get stop_id from stop_name\n",
    "def get_stop_id(stop_name):\n",
    "    return stops[stops['stop_name']==stop_name].iloc[0]['stop_id']\n",
    "\n",
    "#Transform a nested dictionary to a dataframe\n",
    "def nested_dict_to_df(dic):\n",
    "    return pd.json_normalize(dic, sep='_')\n",
    "    \n",
    "    \n",
    "#Transform the route dictionary to the dataframe used in plotting the map\n",
    "def route_to_correct_plot_format(route):\n",
    "    #Add an extra row containing the first stop for easier plotting\n",
    "    route = pd.concat([pd.DataFrame({'current_stop_name': route.iloc[0]['parent_stop_name'],\n",
    "                                'route_cum_confidence':route.iloc[0]['route_cum_confidence'],\n",
    "                                'successor_lat': network.get_node(route.iloc[0]['route_src_id']).lat,\n",
    "                                'successor_lon': network.get_node(route.iloc[0]['route_src_id']).lon,\n",
    "                                'route_trip_id': route.iloc[0]['route_trip_id'],\n",
    "                                'route_dest_arrival_time': route.iloc[0]['route_src_arrival_time'],\n",
    "                                'route_route_short_name': route.iloc[0]['route_route_short_name'],}, index=[0]),\n",
    "                       route], ignore_index=True)\n",
    "    route.rename(columns={'successor_lon': 'lon','successor_lat': 'lat'},inplace=True)\n",
    "    \n",
    "    #Add an column displaying if the stop is a stopover or not\n",
    "    is_stop=list(map(int, route['route_route_short_name'].ne(route['route_route_short_name'].shift(periods=-1)).tolist()))\n",
    "    is_stop[0]=1\n",
    "    route['is_start_stop'] = is_stop\n",
    "    \n",
    "    return route\n",
    "\n",
    "\n",
    "#Display the map on an easy readable format\n",
    "def route_to_print(route):\n",
    "    first = (route.groupby('route_route_short_name').apply(lambda x: x.iloc[0])\n",
    "                   [['route_route_short_name', 'parent_stop_name', 'route_src_departure_time']]\n",
    "                  )\n",
    "    second = (route.groupby('route_route_short_name').apply(lambda x: x.iloc[-1])\n",
    "                   [['current_stop_name', 'route_dest_arrival_time', 'route_cum_confidence']]\n",
    "                  )\n",
    "    \n",
    "    finished = first.join(second)\n",
    "    \n",
    "    finished.columns = ['Route', 'Origin','Departure Time', 'Destination', 'Arrival Time', 'Confidence']\n",
    "    finished = finished[['Route', 'Origin', 'Departure Time', 'Destination', 'Arrival Time', 'Confidence']]\n",
    "    finished = finished.sort_values('Departure Time')\n",
    "    return finished\n",
    "\n",
    "\n",
    "#Create a list of what each marker should display when hovered over\n",
    "def route_format_for_hovering(route, route_stopovers):\n",
    "    route_info_origin=['{0}<br>Take route: {1} at {2}'.format(route['current_stop_name'].iloc[0],\n",
    "                                                                         route['route_route_short_name'].iloc[0],\n",
    "                                                                         route['route_dest_arrival_time'].iloc[0])]\n",
    "    route_info=[]\n",
    "    for i in range(1,route.shape[0]-1):\n",
    "        if route['current_stop_name'].iloc[i] in (route_stopovers['Origin'].values):\n",
    "            route_info.append('{0}<br>Arrive at {1}<br>Switch to route {2} leaving at {3}'\n",
    "                          .format(route['current_stop_name'].iloc[i],\n",
    "                                  route['route_dest_arrival_time'].iloc[i],\n",
    "                                  route['route_route_short_name'].iloc[i+1],\n",
    "                                  route['route_src_departure_time'].iloc[i+1]))\n",
    "        else:\n",
    "            route_info.append('')                      \n",
    "    \n",
    "    route_info_destination=['{0}<br>Arrive at {1}'.format(route['current_stop_name'].iloc[-1],\n",
    "                                  route['route_dest_arrival_time'].iloc[-1])]\n",
    "    return route_info_origin+route_info+route_info_destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68f7de-f6ac-4af6-9024-3172fe040237",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "#Set map token\n",
    "mapbox_token = \"pk.eyJ1IjoiYW5kcmVhc2FhcnIiLCJhIjoiY2wycndzcnhzMDBjdzNmcWxucGd5Y3U2ZiJ9.MVb6asnl_U4lPBj5KKv1DQ\"\n",
    "px.set_mapbox_access_token(mapbox_token)\n",
    "\n",
    "#Plot the map\n",
    "def display_map(route):\n",
    "    #Transform the route dictionary to dataframe\n",
    "    route=nested_dict_to_df(route)\n",
    "    \n",
    "    #Correct the format of the route for correct plotting\n",
    "    route=route_to_correct_plot_format(route)\n",
    "    \n",
    "    #Plot map\n",
    "    fig = go.Figure(go.Scattermapbox(\n",
    "                    mode = \"markers\",\n",
    "                    lat = route['lat'],\n",
    "                    lon = route['lon'],\n",
    "                    #Set dot settings\n",
    "                    marker=go.scattermapbox.Marker(\n",
    "                        color = 'green', \n",
    "                        size=route['is_start_stop']*10),\n",
    "                    #Set hoverinfo to stop_name\n",
    "                    text=route_format_for_hovering(route, route_to_print(route)),\n",
    "                    hoverinfo='text'\n",
    "        ))\n",
    "    \n",
    "    #Add lines to plot\n",
    "    fig.add_trace(go.Scattermapbox(   \n",
    "            lat = route['lat'],\n",
    "            lon = route['lon'],\n",
    "            mode = 'lines+text',\n",
    "            line = dict(\n",
    "                color = 'green',\n",
    "            ),\n",
    "            text=[\"Origin\"]+[\"\" for i in range(len(route)-2)]+[\"Destination\"],\n",
    "            textfont=dict(size=15),\n",
    "            hoverinfo='none'\n",
    "        )) \n",
    "    \n",
    "\n",
    "    #Set initial map\n",
    "    fig.update_layout(\n",
    "        mapbox = {\n",
    "            'accesstoken': mapbox_token,\n",
    "            'style': \"outdoors\", \n",
    "            'zoom': 11,\n",
    "\n",
    "            \n",
    "            'center': go.layout.mapbox.Center(\n",
    "                lat=47.3769,\n",
    "                lon=8.5417\n",
    "            )},\n",
    "        width=1000,\n",
    "        height=700,\n",
    "        showlegend = False)\n",
    "    \n",
    "    fig.update_traces(visible=True, selector=dict(type='scattermapbox'))\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9ac04-80e8-439a-aa1b-7de1ca1a50b9",
   "metadata": {},
   "source": [
    "### Testing of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71867ed3-659a-4fa5-b9b8-e76adad45f70",
   "metadata": {},
   "source": [
    "### Test 1\n",
    "\n",
    "In our first test we display a short trip within the Zurich city center. The trip goes from Zürich, Saalsporthalle to Zürich, Bahnhofquai/HB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b90ec-b6a6-432c-8d7e-e753791176f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "%time routes = query_routes('8591329', '8587349','2022-05-26 10:20:00.0', 0.8)\n",
    "route_times = [route[0].get('route').get('src_arrival_time') for route in routes]\n",
    "route_indices = np.flip(np.argsort(route_times))\n",
    "routes = list(np.asarray(routes)[route_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f971c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "route_to_print(nested_dict_to_df(routes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a841b8-2c24-46ee-8c4c-463d16c47ff4",
   "metadata": {},
   "source": [
    "When comparing the alternative nr. 1 recommended by our model to the one on Google Maps, we get the exact same route and timetable. Below you see our route displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320a4a6-d4a1-42c1-a616-5c1e96b600b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "display_map(routes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0e01f-868e-4402-8cb9-34517141ea16",
   "metadata": {},
   "source": [
    "The route Google Maps proposed:\n",
    "\n",
    "https://drive.google.com/file/d/1QE0tMuJMgoFCP3LjJ_mgI-5613pNHvIG/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c7385-0420-4e6a-93e2-22e8b11b6dfe",
   "metadata": {},
   "source": [
    "### Test 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b13db0-a515-4098-a05d-0591ac5b8e75",
   "metadata": {},
   "source": [
    "Here you see a more complex test. When comparing this route with the one proposed by Google, our model wants to depart at 14.15, while Google Maps proposes a route leaving at 14.27. This can be explained by one of the limits of our model, the maximum walking distance is set to 500 meters. While Google Maps suggests walking the last 600 meters, our model chooses to travel by bus one stop explaining why we need to leave early to make that bus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922e4de-1199-471e-87c1-4974f7e98495",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "%time routes = query_routes('8591385', '8591053','2022-05-26 14:59:00.0', 0.6)\n",
    "if len(routes)>0:\n",
    "    route_times = [route[0].get('route').get('src_arrival_time') for route in routes]\n",
    "    route_indices = np.flip(np.argsort(route_times))\n",
    "    routes = list(np.asarray(routes)[route_indices])\n",
    "else:\n",
    "    print(\"We aplogize, no route meet these criteria\")\n",
    "    print(\"Please lower your confidence level or use a later arrival by time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69d4b5-b459-461b-a837-750e06562319",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "route_to_print(nested_dict_to_df(routes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68306d40-a3a0-4f9b-9234-bc41beaef168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "display_map(routes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c55daa-7a72-4aaf-ae5e-8007d66c60e8",
   "metadata": {},
   "source": [
    "The route Google Maps proposed:\n",
    "\n",
    "https://drive.google.com/file/d/1BVGJceSUvgGFghel1VPSbSTB0eViH1As/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bbe15d",
   "metadata": {},
   "source": [
    "### Test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde05449-64ea-40ec-8ddc-aa6560dc71f1",
   "metadata": {},
   "source": [
    "When we ran this test, we got a slightly better result than the route google maps proposed. This may be because route 916 no longer exists as Google Maps instead proposes walking to route 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172dd66-f989-49ef-8e51-f508d783c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "%time routes = query_routes('8591109', '8596007','2022-05-26 14:59:00', 0)\n",
    "if len(routes)>0:\n",
    "    route_times = [route[0].get('route').get('src_arrival_time') for route in routes]\n",
    "    route_indices = np.flip(np.argsort(route_times))\n",
    "    routes = list(np.asarray(routes)[route_indices])\n",
    "else:\n",
    "    print(\"We aplogize, no route meet these criteria\")\n",
    "    print(\"Please lower your confidence level or use a later arrival by time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b55452-bf7e-4351-b885-52409a153aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "route_to_print(nested_dict_to_df(routes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2485212-1ae5-4d34-a94f-2e72b311c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "display_map(routes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0483e5f0-ad06-4224-b0dc-33b0f9e4dc93",
   "metadata": {},
   "source": [
    "The route Google Maps proposed:\n",
    "\n",
    "https://drive.google.com/file/d/1h4BTUb1iMpqX433NAgRnju2wJyYDVTmz/view?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f8f8f-7e0e-4cc2-9270-a1381ce46830",
   "metadata": {},
   "source": [
    "### Test 4\n",
    "We did not find any route between the two locations in this test. This is contrary to our filtering which should ensure that the network is fully connected. We believe that an error in how we iterate over the walking connections can explain this. We haven't figured the exact problem, but we should at least change the function `get_all_successor_stop_ids` in the `Node` class. This is a limit of our model, which can be improved in future iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07edef6-8464-4c08-b9f7-41a6cd7a1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "%time routes = query_routes('8572595', '8590565','2022-05-26 14:59:00.0', 0.6)\n",
    "if len(routes)>0:\n",
    "    route_times = [route[0].get('route').get('src_arrival_time') for route in routes]\n",
    "    route_indices = np.flip(np.argsort(route_times))\n",
    "    routes = list(np.asarray(routes)[route_indices])\n",
    "else:\n",
    "    print(\"We aplogize, no route meet these criteria\")\n",
    "    print(\"Please lower your confidence level or use a later arrival by time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2862c2a2-19dc-4f96-ac45-bdc748dfc4f3",
   "metadata": {},
   "source": [
    "The route Google Maps proposes:\n",
    "    \n",
    "https://drive.google.com/file/d/1ipr41yssHcJU6Z2iEQ7vaunc8Tz5hi2C/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b7901-9c9e-4916-802f-38d4de954952",
   "metadata": {},
   "source": [
    "We did also test other routes, and the testing made us debug the code. For example, we realized we did not look up walking connections in the correct way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1135d-52b9-485e-ad51-1250248ff1d8",
   "metadata": {},
   "source": [
    "# Application\n",
    "By running the cell below, you can test our application. You type in an origin location, destination location, arrival time and confidence level and click the Search Route button. It may take some time to display the route, so you need to be patient.\n",
    "When finished loading the different route alternatives, you get the option to choose which alternative you want to display. By clicking on one of them, you can see both the map showing the route and a table with the necessary information to tell you when to do switches. Also note the hovering information on the nodes. If you don't know what stops you want to search for, the very last cell of the notebook shows you some random stops you can use. If after some iterations, the plot does not work anymore, please run the cells below the title Test of Results, and it should work again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e08ff7-f795-4a74-9be9-c66d9c6ed101",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "out = widgets.Output()\n",
    "\n",
    "#Function run when search_button is clicked\n",
    "@out.capture(clear_output=True)\n",
    "def on_button_click(b):\n",
    "    string='<b>Loading routes from {0} to {1}....</b>'.format(source.value, destination.value)\n",
    "    display(HTML(string))\n",
    "    try:\n",
    "        #Extract the shortest path\n",
    "        routes = query_routes(get_stop_id(source.value), get_stop_id(destination.value), time.value, float(certainty.value))\n",
    "        w = widgets.Select(\n",
    "        options=['{}th alternative'.format(i) for i in range(1,len(routes)+1)],\n",
    "        #value='1th alternative',\n",
    "        description='Select alternative to plot:',\n",
    "        )\n",
    "\n",
    "        output2 = widgets.Output()\n",
    "\n",
    "        display(w, output2)\n",
    "        def on_value_change(change):\n",
    "            with output2:\n",
    "                output2.clear_output()\n",
    "                print(\"Chosen: \" + change['new'])\n",
    "                display(route_to_print(nested_dict_to_df(routes[int(change['new'][0])-1])))\n",
    "                fig=display_map(routes[int(change['new'][0])-1])\n",
    "                fig.show()\n",
    "\n",
    "        w.observe(on_value_change, names='value')\n",
    "    except IndexError:\n",
    "        display(Text('Invalid stop name, try another stop'))\n",
    "    \n",
    "#Display the input fields\n",
    "display(vcontainer)\n",
    "\n",
    "#Load output when we click on the button\n",
    "display(search_button)\n",
    "display(out)\n",
    "search_button.on_click(on_button_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac634a74-5a1e-40df-9e71-09f937a40dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "# run this cell if you want random suggestions to stops\n",
    "stops.sample(frac=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5c135-4158-4567-adda-cd925a3ee7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
